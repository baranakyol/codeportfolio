---
title: "ba2500 Time Series Homework 4"
author: "Baran Akyol"
date: "November 7, 2016"
output: pdf_document
---


```{r, include=FALSE}

library("xts") #for time series
library("nloptr") #for optimization
library(zoo)
library("dygraphs") #for plots
library("magrittr") # pipes
library(dplyr)
#library(streamgraph)
#library(viridis)

library(quantmod)
library(lattice)
library(timeSeries)
library(rugarch)

```


```{r, message=FALSE, warning=FALSE}
getSymbols("^GSPC", from="2004-01-01")

```


```{r}
spReturns = diff(log(Cl(GSPC)))
spReturns[as.character(head(index(Cl(GSPC)),1))] = 0
```


```{r}
windowLength <- 500
foreLength <- length(spReturns) - windowLength
forecasts <- matrix(NA,foreLength+1,2)
```



```{r, eval=FALSE, include=FALSE}

if (1==1)
{
  for (d in 0:foreLength) {
    #2. Obtain the S&P500 rolling window for this day
      spReturnsOffset = spReturns[(1+d):(windowLength+d)]
  
      #3. Fit the ARIMA model
      final.aic <- Inf
      final.order <- c(0,0,0)
      for (p in 0:5) for (q in 0:5) {
      #for (p in 1) for (q in 0) {
          if ( p == 0 && q == 0) {
              next
          }
  
          arimaFit = tryCatch( arima(spReturnsOffset, order=c(p, 0, q)),
                               error=function( err ) FALSE,
                               warning=function( err ) FALSE )
          #4. if we got the fit return update the AIC else move to the next model.
          if( !is.logical( arimaFit ) ) {
              current.aic <- AIC(arimaFit)
              if (current.aic < final.aic) {
                  final.aic <- current.aic
                  final.order <- c(p, 0, q)
                  final.arima <- arima(spReturnsOffset, order=final.order)
              }
          } else {
              next
          }
      }
  
      #7. Specify the ARMA(p,q)-GARCH(1,1) model with Student-t innovations  to fit
      spec = ugarchspec(
          variance.model=list(garchOrder=c(1,1)),
          mean.model=list(armaOrder=c(final.order[1], final.order[3]), include.mean=T),
          distribution.model="std"
      )
      #8. Fit the ARMA(p,q)-GARCH(1,1) model
      fit = tryCatch(
        ugarchfit(
          spec, spReturnsOffset, solver = 'hybrid'
        ), error=function(e) e, warning=function(w) w
      )
  
      #9. If the GARCH model does not converge, set the direction to "long" else
      # choose the correct forecast direction based on the returns prediction
      # Output the results to the screen and the forecasts vector
      if(is(fit, "warning") || is(fit,"error") ) {
        forecasts[d+1,1] = index(spReturnsOffset)[windowLength]
        forecasts[d+1,2] = 1
        print("warning or error")
        print(paste(paste('Date: ',index(spReturnsOffset)[windowLength],sep=''), paste(' Signal = ',1,sep=''),paste(' Progress = ',paste(round(10000*d/foreLength)/100,'%',sep=''),sep=''), sep=";")) 
      } else {
        #10 compute the one-step-ahead forecast and store the trading decision {-1,1}
        fore = ugarchforecast(fit, n.ahead=1)
        ind = fore@forecast$seriesFor
        forecasts[d+1,1] = index(spReturnsOffset)[windowLength]
        forecasts[d+1,2] = ifelse(ind[1] < 0, -1, 1)
        #print the date 
        print(paste(paste('Date: ',index(spReturnsOffset)[windowLength],sep=''), paste(' Signal = ',ifelse(ind[1] < 0, -1, 1),sep=''),paste(' Progress = ',paste(round(10000*d/foreLength)/100,'%',sep=''),sep=''), sep=";")) 
      }
}

write.csv(forecasts, file="forecasts.csv", row.names=FALSE,quote=FALSE)

}
``` 

# Input the CSV file

```{r}
forecastcsv <-read.csv(file="/Users/mehmetyilmaz/Desktop/TSHW4/forecasts.csv", header=T, sep=",",dec = ".")



spArimaGarch2 <- as.xts(forecastcsv$V2,order.by=as.Date(forecastcsv$V1))
spArimaGarch2 <- lag(spArimaGarch2)


```

# Create the ARIMA+GARCH returns

```{r}

spIntersect         <- merge( spArimaGarch2[,1], spReturns)
spArimaGarchReturns <- spIntersect[,1] * spIntersect[,2]

```

# Create the backtests for ARIMA+GARCH and Buy & Hold

```{r}

#merge the two time series of returns
spCombined <-merge(spArimaGarchReturns,spIntersect[,2],all=F)

#exclude NA and compute cumulative log-returns 
spCombinedCurve   <-(1+cumsum(na.exclude(spCombined)))

```

# Plot the two time series of cumulative returns on one figure

```{r}

dygraph(spCombinedCurve) %>%
  dyRangeSelector()  %>% 
  dyOptions(axisLineWidth = 1.5, fillGraph = FALSE, drawGrid = FALSE, rightGap=50)

```

# --------------------------------------------------------------------------------------------
```{r}
getSymbols("AAPL",src='yahoo', from="2010-11-08")

```



```{r}
AAPLReturns = diff(log(Ad(AAPL)))
AAPLReturns[as.character(head(index(Ad(AAPL)),1))] = 0
```



```{r}
windowLength <- 500
foreLength <- length(AAPLReturns) - windowLength
forecasts2 <- matrix(NA,foreLength+1,2)
```


```{r, eval=FALSE, include=FALSE}
if (1==1)
{
  for (d in 0:foreLength) {

    
      AAPLReturnsOffset = AAPLReturns[(1+d):(windowLength+d)]
  
      #3. Fit the ARIMA model
      final.aic <- Inf
      final.order <- c(0,0,0)
      for (p in 0:5) for (q in 0:5) {
      #for (p in 1) for (q in 0) {
          if ( p == 0 && q == 0) {
              next
          }
  
          arimaFit = tryCatch( arima(AAPLReturnsOffset, order=c(p, 0, q)),
                               error=function( err ) FALSE,
                               warning=function( err ) FALSE )
          #4. if we got the fit return update the AIC else move to the next model.
          if( !is.logical( arimaFit ) ) {
              current.aic <- AIC(arimaFit)
              if (current.aic < final.aic) {
                  final.aic <- current.aic
                  final.order <- c(p, 0, q)
                  final.arima <- arima(AAPLReturnsOffset, order=final.order)
              }
          } else {
              next
          }
      }
  
      #7. Specify the ARMA(p,q)-GARCH(1,1) model with Student-t innovations  to fit
      spec = ugarchspec(
          variance.model=list(garchOrder=c(1,1)),
          mean.model=list(armaOrder=c(final.order[1], final.order[3]), include.mean=T),
          distribution.model="std"
      )
      #8. Fit the ARMA(p,q)-GARCH(1,1) model
      fit = tryCatch(
        ugarchfit(
          spec, AAPLReturnsOffset, solver = 'hybrid'
        ), error=function(e) e, warning=function(w) w
      )
  
      #9. If the GARCH model does not converge, set the direction to "long" else
      # choose the correct forecast direction based on the returns prediction
      # Output the results to the screen and the forecasts vector
      if(is(fit, "warning") || is(fit,"error") ) {
        forecasts2[d+1,1] = index(AAPLReturnsOffset)[windowLength]
        forecasts2[d+1,2] = 1
        print("warning or error")
        print(paste(paste('Date: ',index(AAPLReturnsOffset)[windowLength],sep=''), paste(' Signal = ',1,sep=''),paste(' Progress = ',paste(round(10000*d/foreLength)/100,'%',sep=''),sep=''), sep=";")) 
      } else {
        #10 compute the one-step-ahead forecast and store the trading decision {-1,1}
        fore = ugarchforecast(fit, n.ahead=1)
        ind = fore@forecast$seriesFor
        forecasts2[d+1,1] = index(AAPLReturnsOffset)[windowLength]
        forecasts2[d+1,2] = ifelse(ind[1] < 0, -1, 1)
        #print the date 
        print(paste(paste('Date: ',index(AAPLReturnsOffset)[windowLength],sep=''), paste(' Signal = ',ifelse(ind[1] < 0, -1, 1),sep=''),paste(' Progress = ',paste(round(10000*d/foreLength)/100,'%',sep=''),sep=''), sep=";")) 
      }
}

  
write.csv(forecasts2, file="forecastsAAPL.csv", row.names=FALSE,quote=FALSE)

}
```

# Input the AAPL CSV file

```{r}
forecastAAPLcsv <-read.csv(file="/Users/mehmetyilmaz/Desktop/TSHW4/forecastsAAPL.csv", header=T, sep=",",dec = ".")



AAPLArimaGarch2 <- as.xts(forecastAAPLcsv$V2,order.by=as.Date(forecastAAPLcsv$V1))
AAPLArimaGarch2 <- lag(AAPLArimaGarch2)


```

# Create the ARIMA+GARCH returns

```{r}

AAPLIntersect         <- merge( spArimaGarch2[,1], AAPLReturns)
AAPLArimaGarchReturns <- spIntersect[,1] * spIntersect[,2]

```

# Create the backtests for ARIMA+GARCH and Buy & Hold

```{r}

AAPLCombined <-merge(AAPLArimaGarchReturns,AAPLIntersect[,2],all=F)

AAPLCombinedCurve   <-(1+cumsum(na.exclude(spCombined)))


```

# Plot the two time series of cumulative returns on one figure

```{r}

dygraph(AAPLCombinedCurve) %>%
  dyRangeSelector()  %>% 
  dyOptions(axisLineWidth = 1.5, fillGraph = FALSE, drawGrid = FALSE, rightGap=50)

```

#Sharpe AAPL
```{r}
AAPLmean = apply(AAPLArimaGarch2,2,mean,na.rm=T)
AAPLsd = apply(AAPLArimaGarch2,2,sd,na.rm=T)

252*AAPLmean
sqrt(252)*AAPLsd
AAPLsharpe = sqrt(252)*AAPLmean/AAPLsd
AAPLsharpe



```

#Sharpe S&P
```{r}
SPmean = apply(spArimaGarch2,2,mean,na.rm=T)
SPsd = apply(spArimaGarch2,2,sd,na.rm=T)

252*SPmean
sqrt(252)*SPsd
SPsharpe = sqrt(252)*SPmean/SPsd
SPsharpe


```

```{r}
nnAR3 <- function(data1,p,q,weights)
{
  T1 <- dim(data1)[1]
  maxs <- apply(data1, 2, max) 
  mins <- apply(data1, 2, min)
  scaled <- as.data.frame(scale(data1, center = mins, scale = maxs - mins))
  
  
  Y <- scaled[4:T1,1]
  X <- c(scaled[3:(T1-1),1],scaled[2:(T1-2),1],scaled[1:(T1-3),1])
  X <- matrix(X,length(X)/3,3)
  
  f  <- as.formula("Y ~ X[,1] + X[,2] + X[,3]")
  if (q>0){
    nn1 <- neuralnet(f,data=scaled,hidden=c(p,q),linear.output=T,startweights=weights)  
  }else #q=0 corresponds to a NN with one hidden layer and p neurons
  {
    nn1 <- neuralnet(f,data=scaled,hidden=p,linear.output=T,startweights=weights)  
  }
  pr.nn   <- compute(nn1,t(c(scaled[T1,1],scaled[(T1-1),1],scaled[(T1-2),1])))
  pr.nn_  <- pr.nn$net.result*( maxs - mins ) + mins
  nn1$pr  <- pr.nn
  nn1$pr_ <- pr.nn_
  
  return(nn1)
}


```


```{r}


P=5;Q=5;
nnAll=matrix(list(),P,Q+1)

  for (d in 0:foreLength) {


  spReturnsOffset = spReturns[(1+d):(windowLength+d)]
  T    <- dim(spReturnsOffset)[1]
  FMSE <- matrix(NA,P,Q+1)
  for (p in 1:P) for (q in 0:Q) {
    
    pr1  <- nnAR3(spReturnsOffset[1:(T-1),1],p,q,nnAll[[p,q+1]]$weights)$pr_
    pr2  <- nnAR3(spReturnsOffset[1:(T-2),1],p,q,nnAll[[p,q+1]]$weights)$pr_
    pr3  <- nnAR3(spReturnsOffset[1:(T-3),1],p,q,nnAll[[p,q+1]]$weights)$pr_
    
    FMSE[p,q+1] <- (as.numeric(spReturnsOffset[T,1]) - pr1)^2 +
                     (as.numeric(spReturnsOffset[(T-1),1]) - pr2)^2 +
                     (as.numeric(spReturnsOffset[(T-2),1]) - pr3)^2
    
    #run all the cases on full data, to store the starting values for the next rolling window
    nn  <- nnAR3(spReturnsOffset[1:T,1],p,q,nnAll[[p,q+1]]$weights)
    nnAll[[p,q+1]]=nn
  }

  
  p1 <- which(FMSE == min(FMSE), arr.ind = TRUE)[1]
  q1 <- which(FMSE == min(FMSE), arr.ind = TRUE)[2]
  ind <- index(spReturns[windowLength+d+1])
  nnOpt  <- nnAll[[p1,q1]]
  pr  <- nnOpt$pr_
  }
      
```


```{r}
install.packages('locfit')
install.packages('bootstrap')
install.packages('bisoreg')

library('locfit')
library('bootstrap')
library('bisoreg')

# Make example reproducible
set.seed(19)

# Create a curve with noise
x <- 1:120

#signal function
g_signal <- function(x,period){ return(sin(2*pi*x/period)) }

period <- 120

ynonoise <- g_signal(x,period)

y <- g_signal(x,period) + runif(length(x),-1,1)


# Plot points on noisy curve
plot(x,y, main="Signal Curve + 'Uniform' Noise")
mtext("showing loess smoothing (local regression smoothing)")

lines(x,ynonoise,col='blueviolet',lwd=5)

#5-fold Cross Validation to select optimal bandwidth for loess
yloess5 <-loess.wrapper(x, y, span.vals = seq(0.25, 1, by = 0.05), folds = 5)




spanlist <- c(yloess5$s, 0.1, 0.5, 1, 1.5, 2)

for (i in 1:length(spanlist))
{
  y.loess <- loess(y ~ x, data.frame(x=x, y=y), span=spanlist[i])
  y.predict <- predict(y.loess, data.frame(x=x))
  
  # Plot the loess smoothed curve
  lines(x,y.predict,col=i)
  
  # Find peak point on smoothed curve
  peak <- optimize(function(x, model)
    predict(model, data.frame(x=x)),
    c(min(x),max(x)),
    maximum=TRUE,
    model=y.loess)
  
  # Show position of smoothed curve maximum
  points(peak$maximum,peak$objective, pch=FILLED.CIRCLE<-19, col=i)
}

legend (0,-0.8,
        c(paste("span=", formatC(spanlist, digits=2, format="f"))),
        lty=SOLID<-1, col=1:length(spanlist), bty="n")

# Make example reproducible
set.seed(19)

FullList <- 1:120
x <- FullList

ynonoise <- g_signal(x,period)

# "randomly" make 15 of the points "missing"
MissingList <- sample(x,15)
x[MissingList] <- NA

# Create sine curve with noise
y <- g_signal(x,period) + runif(length(x),-1,1)


# Plot points on noisy curve
plot(x,y, main="Sine Curve + 'Uniform' Noise")
lines(FullList,ynonoise,col='blueviolet',lwd=5)
mtext("Using loess smoothed fit to impute missing values")

#5-fold Cross Validation to select optimal bandwidth for loess
yloess5 <-loess.wrapper(x, y, span.vals = seq(0.25, 1, by = 0.05), folds = 5)

spanlist <- c(yloess5$s, 0.1, 0.5, 1, 1.5, 2)

for (i in 1:length(spanlist))
{
  y.loess <- loess(y ~ x, span=spanlist[i], data.frame(x=x, y=y))
  y.predict <- predict(y.loess, data.frame(x=FullList))
  
  # Plot the loess smoothed curve showing gaps for missing data
  lines(x,y.predict,col=i)
  
  # Show imputed points to fill in gaps
  y.Missing <-  predict(y.loess, data.frame(x=MissingList))
  points(MissingList, y.Missing, pch=FILLED.CIRCLE<-19, col=i)
}


legend (0,-0.8, c(paste("span=", formatC(spanlist, digits=2, format="f"))),
        lty=SOLID<-1, col=1:length(spanlist), bty="n")

```

